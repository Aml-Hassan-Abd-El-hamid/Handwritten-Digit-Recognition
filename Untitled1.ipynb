{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d38db5c",
   "metadata": {},
   "source": [
    "# Handwritten Digit Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfa5f9a",
   "metadata": {},
   "source": [
    "A handwritten digit recognizer using MNIST dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d097fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The used packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten,Dense,Conv2D,MaxPooling2D\n",
    "from keras.optimizers import SGD,Adam\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "if len(physical_devices)>0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea38f04",
   "metadata": {},
   "source": [
    "<h2>Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1db608a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n",
      "Type of data is  <class 'numpy.ndarray'> <class 'numpy.uint8'>\n",
      "(28, 28) ()\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]] 5\n"
     ]
    }
   ],
   "source": [
    "(xtr,ytr),(xts,yts) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print(xtr.shape, ytr.shape)\n",
    "print(xts.shape,yts.shape)\n",
    "print('Type of data is ',type(xtr[0]),type(ytr[0]))\n",
    "print(xtr[0].shape,ytr[0].shape)\n",
    "print(xtr[0],ytr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf7416b",
   "metadata": {},
   "source": [
    "<h2> Visualize the digits dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1e33afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'The first ten numbers')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show the first ten numbers\n",
    "#(1,10)= 1 rows, ten columns\n",
    "#x = an array of Axes objects\n",
    "figure,x = plt.subplots(1,10)\n",
    "for i in range(10):\n",
    "    x[i].imshow(xtr[i])\n",
    "    x[i].set_title(ytr[i])\n",
    "    #don't show axis, cuz it's ugly here :(\n",
    "    x[i].axis('off')\n",
    "figure.suptitle(\"The first ten numbers\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaa6e30",
   "metadata": {},
   "source": [
    "<h2>Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6964c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First digit: [5]\n",
      "One-hot-encoded version:\n",
      " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Normalizing the data\n",
    "#using float 16 insted of float 32 since it's more efficient\n",
    "xtr = xtr.astype(np.float16)/255.0\n",
    "xts = xts.astype(np.float16)/255.0\n",
    "#one hot encoding \n",
    "ytr_oh = keras.utils.to_categorical(ytr)\n",
    "yts_oh = keras.utils.to_categorical(yts)\n",
    "print(\"First digit:\",ytr[:1])\n",
    "print(\"One-hot-encoded version:\\n\",ytr_oh[:1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec99ddd0",
   "metadata": {},
   "source": [
    "<h2>Modeling and Toning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1551b1",
   "metadata": {},
   "source": [
    "I started with a small general model and then added more complexity until I started having an overfitting problem, then I moved on to a convolutional neural network. I have built 4 models and the last one was the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f4e9429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3770 - acc: 0.8921 - val_loss: 0.3082 - val_acc: 0.9123\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3033 - acc: 0.9145 - val_loss: 0.2905 - val_acc: 0.9178\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2896 - acc: 0.9182 - val_loss: 0.2785 - val_acc: 0.9210\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2825 - acc: 0.9207 - val_loss: 0.2807 - val_acc: 0.9228\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2773 - acc: 0.9224 - val_loss: 0.2865 - val_acc: 0.9197\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2744 - acc: 0.9237 - val_loss: 0.2748 - val_acc: 0.9219\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2706 - acc: 0.9246 - val_loss: 0.2893 - val_acc: 0.9212\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2693 - acc: 0.9247 - val_loss: 0.2783 - val_acc: 0.9235\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2676 - acc: 0.9262 - val_loss: 0.2734 - val_acc: 0.9231\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2651 - acc: 0.9261 - val_loss: 0.2760 - val_acc: 0.9215\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model1 = Sequential()\n",
    "#the dimension of our digit images is 28×28.Because the input dimension of a fully-connected layer is 784, we need to insert another layer into the network, called Flatten, to change tensor shape from 28×28 to 784\n",
    "model1.add(Flatten(input_shape=(28,28)))\n",
    "#We want th output of the network to return the probability of the input digit being equal to  . Because the output of a fully-connected layer is not normalized to be between 0 and 1, it cannot be thought of as probability. To turn it into a probability we need to apply another layer called Softmax.\n",
    "model1.add(Dense(10,activation=\"softmax\"))\n",
    "           \n",
    "model1.compile(SGD(momentum=0.5,lr=.1),loss='categorical_crossentropy',metrics=['acc'])\n",
    "model1.fit(xtr,ytr_oh,validation_data=(xts,yts_oh), epochs=10)\n",
    "model1.summary()\n",
    "#that model's accuracy is already 92% although it's very simple one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7767751a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/53\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2855 - acc: 0.9118 - val_loss: 0.1499 - val_acc: 0.9516\n",
      "Epoch 2/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1189 - acc: 0.9637 - val_loss: 0.1243 - val_acc: 0.9611\n",
      "Epoch 3/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0859 - acc: 0.9726 - val_loss: 0.0875 - val_acc: 0.9732\n",
      "Epoch 4/53\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0665 - acc: 0.9788 - val_loss: 0.0847 - val_acc: 0.9751\n",
      "Epoch 5/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0531 - acc: 0.9839 - val_loss: 0.0927 - val_acc: 0.9730\n",
      "Epoch 6/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0420 - acc: 0.9866 - val_loss: 0.0768 - val_acc: 0.9766\n",
      "Epoch 7/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0356 - acc: 0.9880 - val_loss: 0.0674 - val_acc: 0.9804\n",
      "Epoch 8/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0310 - acc: 0.9900 - val_loss: 0.0884 - val_acc: 0.9745\n",
      "Epoch 9/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0263 - acc: 0.9914 - val_loss: 0.0815 - val_acc: 0.9786\n",
      "Epoch 10/53\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0209 - acc: 0.9934 - val_loss: 0.0862 - val_acc: 0.9754\n",
      "Epoch 11/53\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0186 - acc: 0.9941 - val_loss: 0.0980 - val_acc: 0.9741\n",
      "Epoch 12/53\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0172 - acc: 0.9944 - val_loss: 0.0906 - val_acc: 0.9790\n",
      "Epoch 13/53\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0150 - acc: 0.9951 - val_loss: 0.0932 - val_acc: 0.9776\n",
      "Epoch 14/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0110 - acc: 0.9967 - val_loss: 0.0879 - val_acc: 0.9795\n",
      "Epoch 15/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0071 - acc: 0.9978 - val_loss: 0.0920 - val_acc: 0.9799\n",
      "Epoch 16/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0078 - acc: 0.9975 - val_loss: 0.1013 - val_acc: 0.9790\n",
      "Epoch 17/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0128 - acc: 0.9956 - val_loss: 0.1115 - val_acc: 0.9785\n",
      "Epoch 18/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0141 - acc: 0.9952 - val_loss: 0.0908 - val_acc: 0.9802\n",
      "Epoch 19/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0064 - acc: 0.9980 - val_loss: 0.0935 - val_acc: 0.9804\n",
      "Epoch 20/53\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0037 - acc: 0.9989 - val_loss: 0.0921 - val_acc: 0.9818\n",
      "Epoch 21/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0934 - val_acc: 0.9830\n",
      "Epoch 22/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 3.7078e-04 - acc: 1.0000 - val_loss: 0.0924 - val_acc: 0.9832\n",
      "Epoch 23/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 2.0408e-04 - acc: 1.0000 - val_loss: 0.0943 - val_acc: 0.9830\n",
      "Epoch 24/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.5965e-04 - acc: 1.0000 - val_loss: 0.0962 - val_acc: 0.9834\n",
      "Epoch 25/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.3688e-04 - acc: 1.0000 - val_loss: 0.0973 - val_acc: 0.9833\n",
      "Epoch 26/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.1868e-04 - acc: 1.0000 - val_loss: 0.0987 - val_acc: 0.9834\n",
      "Epoch 27/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.0674e-04 - acc: 1.0000 - val_loss: 0.0994 - val_acc: 0.9836\n",
      "Epoch 28/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 9.6784e-05 - acc: 1.0000 - val_loss: 0.1000 - val_acc: 0.9837\n",
      "Epoch 29/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 8.8593e-05 - acc: 1.0000 - val_loss: 0.1008 - val_acc: 0.9834\n",
      "Epoch 30/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 8.2042e-05 - acc: 1.0000 - val_loss: 0.1013 - val_acc: 0.9835\n",
      "Epoch 31/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 7.6562e-05 - acc: 1.0000 - val_loss: 0.1021 - val_acc: 0.9837\n",
      "Epoch 32/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 7.1374e-05 - acc: 1.0000 - val_loss: 0.1028 - val_acc: 0.9836\n",
      "Epoch 33/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 6.7157e-05 - acc: 1.0000 - val_loss: 0.1033 - val_acc: 0.9835\n",
      "Epoch 34/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 6.3505e-05 - acc: 1.0000 - val_loss: 0.1040 - val_acc: 0.9836\n",
      "Epoch 35/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 6.0259e-05 - acc: 1.0000 - val_loss: 0.1042 - val_acc: 0.9838\n",
      "Epoch 36/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 5.7322e-05 - acc: 1.0000 - val_loss: 0.1051 - val_acc: 0.9837\n",
      "Epoch 37/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 5.4717e-05 - acc: 1.0000 - val_loss: 0.1054 - val_acc: 0.9836\n",
      "Epoch 38/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 5.2271e-05 - acc: 1.0000 - val_loss: 0.1059 - val_acc: 0.9838\n",
      "Epoch 39/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 5.0073e-05 - acc: 1.0000 - val_loss: 0.1063 - val_acc: 0.9837\n",
      "Epoch 40/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 4.7967e-05 - acc: 1.0000 - val_loss: 0.1069 - val_acc: 0.9837\n",
      "Epoch 41/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 4.6316e-05 - acc: 1.0000 - val_loss: 0.1071 - val_acc: 0.9839\n",
      "Epoch 42/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 4.4525e-05 - acc: 1.0000 - val_loss: 0.1073 - val_acc: 0.9836\n",
      "Epoch 43/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 4.2987e-05 - acc: 1.0000 - val_loss: 0.1078 - val_acc: 0.9838\n",
      "Epoch 44/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 4.1430e-05 - acc: 1.0000 - val_loss: 0.1081 - val_acc: 0.9836\n",
      "Epoch 45/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 4.0082e-05 - acc: 1.0000 - val_loss: 0.1085 - val_acc: 0.9837\n",
      "Epoch 46/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 3.8803e-05 - acc: 1.0000 - val_loss: 0.1089 - val_acc: 0.9835\n",
      "Epoch 47/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 3.7551e-05 - acc: 1.0000 - val_loss: 0.1091 - val_acc: 0.9836\n",
      "Epoch 48/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 3.6474e-05 - acc: 1.0000 - val_loss: 0.1094 - val_acc: 0.9836\n",
      "Epoch 49/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 3.5369e-05 - acc: 1.0000 - val_loss: 0.1098 - val_acc: 0.9836\n",
      "Epoch 50/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 3.4368e-05 - acc: 1.0000 - val_loss: 0.1100 - val_acc: 0.9837\n",
      "Epoch 51/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 3.3493e-05 - acc: 1.0000 - val_loss: 0.1103 - val_acc: 0.9837\n",
      "Epoch 52/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 3.2528e-05 - acc: 1.0000 - val_loss: 0.1105 - val_acc: 0.9836\n",
      "Epoch 53/53\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 3.1769e-05 - acc: 1.0000 - val_loss: 0.1110 - val_acc: 0.9837\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_15 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 99,710\n",
      "Trainable params: 99,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Multi-Layer networks\n",
    "#adding more hidden layers\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model2 = Sequential()\n",
    "#the dimension of our digit images is 28×28.Because the input dimension of a fully-connected layer is 784, we need to insert another layer into the network, called Flatten, to change tensor shape from 28×28 to 784\n",
    "model2.add(Flatten(input_shape=(28,28)))\n",
    "\n",
    "# 784 inputs=28*28, 100 outputs\n",
    "model2.add(Dense(100,activation=\"relu\"))\n",
    "\n",
    "model2.add(Dense(100,activation=\"relu\"))\n",
    "model2.add(Dense(100,activation=\"relu\"))     \n",
    "\n",
    "#We want th output of the network to return the probability of the input digit being equal to  . Because the output of a fully-connected layer is not normalized to be between 0 and 1, it cannot be thought of as probability. To turn it into a probability we need to apply another layer called Softmax.\n",
    "model2.add(Dense(10,activation=\"softmax\"))\n",
    "           \n",
    "model2.compile(SGD(lr=.1),loss='categorical_crossentropy',metrics=['acc'])\n",
    "model2.fit(xtr,ytr_oh,validation_data=(xts,yts_oh), epochs=50)\n",
    "model2.summary()\n",
    "#val_accuracy = .98"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3587cba7",
   "metadata": {},
   "source": [
    "<h4>moving on to CNN:</h4>\n",
    "\n",
    "the layer Conv2D from keras expects the input to be of the shape  W×H×C, where W and H are width and height of the image, and C is the number of color channels. Since the MINST dataset is grayscale, Then we need the same shape with C set to 1 this time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ff9947d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "xtr_c = np.expand_dims(xtr,3)\n",
    "xts_c = np.expand_dims(xts,3)\n",
    "print(xtr_c.shape,xtr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dea0e475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2180 - acc: 0.9364 - val_loss: 0.0966 - val_acc: 0.9720\n",
      "Epoch 2/17\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0862 - acc: 0.9755 - val_loss: 0.0716 - val_acc: 0.9781\n",
      "Epoch 3/17\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0666 - acc: 0.9810 - val_loss: 0.0593 - val_acc: 0.9813\n",
      "Epoch 4/17\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0579 - acc: 0.9833 - val_loss: 0.0677 - val_acc: 0.9787\n",
      "Epoch 5/17\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0529 - acc: 0.9851 - val_loss: 0.0577 - val_acc: 0.9811\n",
      "Epoch 6/17\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0489 - acc: 0.9862 - val_loss: 0.0540 - val_acc: 0.9825\n",
      "Epoch 7/17\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0460 - acc: 0.9868 - val_loss: 0.0560 - val_acc: 0.9828\n",
      "Epoch 8/17\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0445 - acc: 0.9872 - val_loss: 0.0518 - val_acc: 0.9835\n",
      "Epoch 9/17\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0424 - acc: 0.9879 - val_loss: 0.0564 - val_acc: 0.9823\n",
      "Epoch 10/17\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0407 - acc: 0.9884 - val_loss: 0.0524 - val_acc: 0.9837\n",
      "Epoch 11/17\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0393 - acc: 0.9887 - val_loss: 0.0552 - val_acc: 0.9834\n",
      "Epoch 12/17\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0377 - acc: 0.9893 - val_loss: 0.0568 - val_acc: 0.9812\n",
      "Epoch 13/17\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0367 - acc: 0.9897 - val_loss: 0.0527 - val_acc: 0.9834\n",
      "Epoch 14/17\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0359 - acc: 0.9900 - val_loss: 0.0557 - val_acc: 0.9833\n",
      "Epoch 15/17\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0344 - acc: 0.9904 - val_loss: 0.0563 - val_acc: 0.9824\n",
      "Epoch 16/17\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0337 - acc: 0.9903 - val_loss: 0.0546 - val_acc: 0.9838\n",
      "Epoch 17/17\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0324 - acc: 0.9910 - val_loss: 0.0586 - val_acc: 0.9843\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_55 (Conv2D)          (None, 24, 24, 9)         234       \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 5184)              0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                51850     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52,084\n",
      "Trainable params: 52,084\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model3 = keras.models.Sequential()\n",
    "\n",
    "model3.add(Conv2D(filters=9, kernel_size=(5,5), input_shape=(28,28,1),activation='relu'))\n",
    "\n",
    "model3.add(Flatten())\n",
    "\n",
    "model3.add(Dense(10,activation=\"softmax\"))\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy',metrics=['acc'])\n",
    "\n",
    "model3.fit(xtr_c,ytr_oh,validation_data=(xts_c,yts_oh),epochs=17)\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f039e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.2177 - acc: 0.9321 - val_loss: 0.0780 - val_acc: 0.9742\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0607 - acc: 0.9817 - val_loss: 0.0525 - val_acc: 0.9822\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0406 - acc: 0.9870 - val_loss: 0.0347 - val_acc: 0.9889\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0329 - acc: 0.9901 - val_loss: 0.0454 - val_acc: 0.9859\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0275 - acc: 0.9920 - val_loss: 0.0324 - val_acc: 0.9902\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0236 - acc: 0.9930 - val_loss: 0.0317 - val_acc: 0.9908\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.0211 - acc: 0.9937 - val_loss: 0.0306 - val_acc: 0.9919\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.0195 - acc: 0.9945 - val_loss: 0.0391 - val_acc: 0.9893\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0163 - acc: 0.9951 - val_loss: 0.0317 - val_acc: 0.9912\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0143 - acc: 0.9958 - val_loss: 0.0343 - val_acc: 0.9919\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_52 (Conv2D)          (None, 24, 24, 20)        520       \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 12, 12, 20)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 8, 8, 20)          10020     \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 4, 4, 20)          10020     \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 2, 2, 20)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                810       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,370\n",
      "Trainable params: 21,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model4 = keras.models.Sequential()\n",
    "\n",
    "model4.add(Conv2D(filters=20, kernel_size=(5,5), input_shape=(28,28,1),activation='relu'))\n",
    "model4.add(MaxPooling2D())\n",
    "\n",
    "model4.add(Conv2D(filters=20, kernel_size=(5,5), activation='relu'))\n",
    "\n",
    "model4.add(Conv2D(filters=20, kernel_size=(5,5), activation='relu'))\n",
    "model4.add(MaxPooling2D())\n",
    "\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(10,activation=\"softmax\"))\n",
    "\n",
    "model4.compile(loss='categorical_crossentropy',metrics=['acc'])\n",
    "\n",
    "model4.fit(xtr_c,ytr_oh,validation_data=(xts_c,yts_oh),epochs=10)\n",
    "model4.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
