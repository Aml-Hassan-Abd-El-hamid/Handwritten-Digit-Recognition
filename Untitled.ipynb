{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b2c67de",
   "metadata": {},
   "source": [
    "# handwritten digits\n",
    "\n",
    "Importing Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "049a79ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 00:55:35.895880: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-30 00:55:35.895982: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 00:55:53.874733: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-07-30 00:55:53.874781: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (aml-HP-ZBook-15-G3): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "#Import the packages needed.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten,Dense,Conv2D\n",
    "from keras.optimizers import SGD\n",
    "import os\n",
    "tf.random.set_seed(42)\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "if len(physical_devices)>0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "print(len(physical_devices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191ac057",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bdd6e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "(xtr,ytr),(xts,yts) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print(xtr.shape, ytr.shape)\n",
    "print(xts.shape,yts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2830eee4",
   "metadata": {},
   "source": [
    "## Visualize the digits dataset And Exploring the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a72d93cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 60000\n",
      "Test data: 10000\n",
      "Tensor shape: (28, 28)\n",
      "Type of data is  <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'The first ten numbers')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Training data:',len(xtr))\n",
    "print('Test data:',len(xts))\n",
    "print('Tensor shape:',xtr[0].shape)\n",
    "print('Type of data is ',type(xtr))\n",
    "\n",
    "#show the first ten numbers\n",
    "#(1,10)= 1 rows, ten columns\n",
    "#x = an array of Axes objects\n",
    "figure,x = plt.subplots(1,10)\n",
    "for i in range(10):\n",
    "    x[i].imshow(xtr[i])\n",
    "    x[i].set_title(ytr[i])\n",
    "#don't show axis, it's ugly here :(\n",
    "    x[i].axis('off')\n",
    "figure.suptitle(\"The first ten numbers\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6055c207",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f7b29fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First digit: [5]\n",
      "One-hot-encoded version:\n",
      " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Normalizing the data\n",
    "#using float 16 insted of float 32 since it's more efficient\n",
    "xtr = xtr.astype(np.float32)/255.0\n",
    "xts = xts.astype(np.float32)/255.0\n",
    "#one hot encoding \n",
    "ytr_oh = keras.utils.to_categorical(ytr)\n",
    "yts_oh = keras.utils.to_categorical(yts)\n",
    "print(\"First digit:\",ytr[:1])\n",
    "print(\"One-hot-encoded version:\\n\",ytr_oh[:1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d30962b",
   "metadata": {},
   "source": [
    "# Modeling and Toneing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa58bd1",
   "metadata": {},
   "source": [
    "for starting I'm going to use a simple sequential model and then build up more complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "200d2ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 00:56:04.394162: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/aml/.local/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3770 - acc: 0.8921 - val_loss: 0.3082 - val_acc: 0.9123\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3033 - acc: 0.9145 - val_loss: 0.2905 - val_acc: 0.9177\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2896 - acc: 0.9182 - val_loss: 0.2785 - val_acc: 0.9210\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2824 - acc: 0.9207 - val_loss: 0.2807 - val_acc: 0.9228\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2773 - acc: 0.9223 - val_loss: 0.2865 - val_acc: 0.9197\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2744 - acc: 0.9237 - val_loss: 0.2748 - val_acc: 0.9219\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2706 - acc: 0.9246 - val_loss: 0.2893 - val_acc: 0.9212\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2693 - acc: 0.9247 - val_loss: 0.2783 - val_acc: 0.9235\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2676 - acc: 0.9262 - val_loss: 0.2734 - val_acc: 0.9231\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2651 - acc: 0.9261 - val_loss: 0.2760 - val_acc: 0.9215\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#starting with a simple model of only 2 layers\n",
    "model1 = Sequential()\n",
    "#the dimension of our digit images is 28×28.Because the input dimension of a fully-connected layer is 784, we need to insert another layer into the network, called Flatten, to change tensor shape from 28×28 to 784\n",
    "model1.add(Flatten(input_shape=(28,28)))\n",
    "#We want th output of the network to return the probability of the input digit being equal to  . Because the output of a fully-connected layer is not normalized to be between 0 and 1, it cannot be thought of as probability. To turn it into a probability we need to apply another layer called Softmax.\n",
    "model1.add(Dense(10,activation=\"softmax\"))\n",
    "           \n",
    "model1.compile(SGD(momentum=0.5,lr=.1),loss='categorical_crossentropy',metrics=['acc'])\n",
    "model1.fit(xtr,ytr_oh,validation_data=(xts,yts_oh), epochs=10)\n",
    "model1.summary()\n",
    "#that model's accuracy is already 92% although it's very simple one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9deeeae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3037 - acc: 0.9118 - val_loss: 0.1725 - val_acc: 0.9469\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1492 - acc: 0.9568 - val_loss: 0.1279 - val_acc: 0.9621\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1091 - acc: 0.9675 - val_loss: 0.0971 - val_acc: 0.9697\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0876 - acc: 0.9742 - val_loss: 0.0931 - val_acc: 0.9709\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0727 - acc: 0.9789 - val_loss: 0.0858 - val_acc: 0.9733\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0620 - acc: 0.9818 - val_loss: 0.0787 - val_acc: 0.9760\n",
      "Epoch 7/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0538 - acc: 0.9841 - val_loss: 0.0790 - val_acc: 0.9750\n",
      "Epoch 8/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0483 - acc: 0.9853 - val_loss: 0.0756 - val_acc: 0.9773\n",
      "Epoch 9/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0419 - acc: 0.9877 - val_loss: 0.0765 - val_acc: 0.9766\n",
      "Epoch 10/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0366 - acc: 0.9893 - val_loss: 0.0754 - val_acc: 0.9779\n",
      "Epoch 11/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0327 - acc: 0.9910 - val_loss: 0.0783 - val_acc: 0.9753\n",
      "Epoch 12/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0284 - acc: 0.9919 - val_loss: 0.0785 - val_acc: 0.9760\n",
      "Epoch 13/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0255 - acc: 0.9929 - val_loss: 0.0756 - val_acc: 0.9787\n",
      "Epoch 14/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0225 - acc: 0.9943 - val_loss: 0.0763 - val_acc: 0.9779\n",
      "Epoch 15/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0195 - acc: 0.9956 - val_loss: 0.0764 - val_acc: 0.9784\n",
      "Epoch 16/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0176 - acc: 0.9958 - val_loss: 0.0736 - val_acc: 0.9773\n",
      "Epoch 17/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0158 - acc: 0.9966 - val_loss: 0.0781 - val_acc: 0.9755\n",
      "Epoch 18/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0143 - acc: 0.9972 - val_loss: 0.0770 - val_acc: 0.9769\n",
      "Epoch 19/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0125 - acc: 0.9974 - val_loss: 0.0772 - val_acc: 0.9778\n",
      "Epoch 20/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0111 - acc: 0.9980 - val_loss: 0.0745 - val_acc: 0.9783\n",
      "Epoch 21/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0100 - acc: 0.9985 - val_loss: 0.0741 - val_acc: 0.9783\n",
      "Epoch 22/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0088 - acc: 0.9989 - val_loss: 0.0801 - val_acc: 0.9766\n",
      "Epoch 23/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0079 - acc: 0.9990 - val_loss: 0.0791 - val_acc: 0.9779\n",
      "Epoch 24/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0069 - acc: 0.9994 - val_loss: 0.0800 - val_acc: 0.9770\n",
      "Epoch 25/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0064 - acc: 0.9995 - val_loss: 0.0810 - val_acc: 0.9785\n",
      "Epoch 26/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0058 - acc: 0.9995 - val_loss: 0.0789 - val_acc: 0.9776\n",
      "Epoch 27/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0054 - acc: 0.9995 - val_loss: 0.0799 - val_acc: 0.9778\n",
      "Epoch 28/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0050 - acc: 0.9996 - val_loss: 0.0801 - val_acc: 0.9782\n",
      "Epoch 29/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0042 - acc: 0.9998 - val_loss: 0.0803 - val_acc: 0.9783\n",
      "Epoch 30/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0040 - acc: 0.9999 - val_loss: 0.0813 - val_acc: 0.9782\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Multi-Layer networks\n",
    "#adding more hidden layers\n",
    "#starting with a simple model of only 2 layers\n",
    "model2 = Sequential()\n",
    "#the dimension of our digit images is 28×28.Because the input dimension of a fully-connected layer is 784, we need to insert another layer into the network, called Flatten, to change tensor shape from 28×28 to 784\n",
    "model2.add(Flatten(input_shape=(28,28)))\n",
    "\n",
    "# 784 inputs, 100 outputs\n",
    "model2.add(Dense(100,activation=\"relu\"))     \n",
    "\n",
    "#We want th output of the network to return the probability of the input digit being equal to  . Because the output of a fully-connected layer is not normalized to be between 0 and 1, it cannot be thought of as probability. To turn it into a probability we need to apply another layer called Softmax.\n",
    "model2.add(Dense(10,activation=\"softmax\"))\n",
    "           \n",
    "model2.compile(SGD(lr=.1),loss='categorical_crossentropy',metrics=['acc'])\n",
    "model2.fit(xtr,ytr_oh,validation_data=(xts,yts_oh), epochs=30)\n",
    "model2.summary()\n",
    "#val_accuracy = .97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a66a42cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2004 - acc: 0.9425 - val_loss: 0.0950 - val_acc: 0.9716\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0858 - acc: 0.9750 - val_loss: 0.0666 - val_acc: 0.9800\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0658 - acc: 0.9808 - val_loss: 0.0583 - val_acc: 0.9822\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0564 - acc: 0.9837 - val_loss: 0.0603 - val_acc: 0.9806\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0513 - acc: 0.9850 - val_loss: 0.0532 - val_acc: 0.9827\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0476 - acc: 0.9868 - val_loss: 0.0499 - val_acc: 0.9846\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0446 - acc: 0.9875 - val_loss: 0.0549 - val_acc: 0.9842\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0430 - acc: 0.9874 - val_loss: 0.0508 - val_acc: 0.9840\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0411 - acc: 0.9890 - val_loss: 0.0576 - val_acc: 0.9836\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0401 - acc: 0.9884 - val_loss: 0.0504 - val_acc: 0.9844\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 9)         234       \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 5184)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                51850     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52,084\n",
      "Trainable params: 52,084\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Multi-level networks can achieve higher accuracy than single-layer perceptron, however, they are not perfect for computer vision tasks. In images, there are some structural patterns that can help us classify an object regardless of it's position in the image, but perceptrons do not allow us to extract those patterns and look for them selectively. In the next unit we will focus on a special type of neural networks that can be used effectively for computer vision tasks.\n",
    "#Trying CNN: Convolutional neural networks\n",
    "#Computer vision is different from generic classification, because when we are trying to find a certain object in the picture, we are scanning the image looking for some specific patterns and their combinations.\n",
    "model3 = keras.models.Sequential()\n",
    "\n",
    "model3.add(Conv2D(filters=9, kernel_size=(5,5), input_shape=(28,28,1),activation='relu'))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(10))\n",
    "\n",
    "model3.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['acc'])\n",
    "\n",
    "x_train_c = np.expand_dims(xtr,3)\n",
    "x_test_c = np.expand_dims(xts,3)\n",
    "hist = model3.fit(x_train_c,ytr,validation_data=(x_test_c,yts),epochs=10)\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce91d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2508 - acc: 0.9252 - val_loss: 0.0933 - val_acc: 0.9703\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0877 - acc: 0.9737 - val_loss: 0.0733 - val_acc: 0.9759\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0649 - acc: 0.9805 - val_loss: 0.0523 - val_acc: 0.9826\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0541 - acc: 0.9835 - val_loss: 0.0540 - val_acc: 0.9843\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0462 - acc: 0.9862 - val_loss: 0.0426 - val_acc: 0.9870\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0408 - acc: 0.9874 - val_loss: 0.0433 - val_acc: 0.9868\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0371 - acc: 0.9890 - val_loss: 0.0470 - val_acc: 0.9865\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0341 - acc: 0.9900 - val_loss: 0.0412 - val_acc: 0.9876\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0313 - acc: 0.9906 - val_loss: 0.0453 - val_acc: 0.9870\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.0286 - acc: 0.9909 - val_loss: 0.0401 - val_acc: 0.9879\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0263 - acc: 0.9922 - val_loss: 0.0460 - val_acc: 0.9870\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0245 - acc: 0.9926 - val_loss: 0.0445 - val_acc: 0.9879\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0218 - acc: 0.9934 - val_loss: 0.0486 - val_acc: 0.9880\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0219 - acc: 0.9933 - val_loss: 0.0531 - val_acc: 0.9860\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0208 - acc: 0.9936 - val_loss: 0.0529 - val_acc: 0.9879\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0188 - acc: 0.9945 - val_loss: 0.0482 - val_acc: 0.9879\n",
      "Epoch 17/20\n",
      " 704/1875 [==========>...................] - ETA: 8s - loss: 0.0158 - acc: 0.9949"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    Conv2D(filters=10, kernel_size=(7,7), input_shape=(28,28,1),activation='relu'),\n",
    "    keras.layers.MaxPooling2D(),\n",
    "    Conv2D(filters=20, kernel_size=(7,7), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(),    \n",
    "    Flatten(),\n",
    "    Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['acc'])\n",
    "xtr_c = np.expand_dims(xtr,3)\n",
    "xts_c = np.expand_dims(xts,3)\n",
    "hist = model.fit(xtr_c,ytr,validation_data=(xts_c,yts),epochs=20)\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
